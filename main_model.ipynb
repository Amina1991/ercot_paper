{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ercot_volatility_analysis.py (Plotly version, cleaned + EGARCH with t-dist + trimming + prep for GARCH-X)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from arch import arch_model\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt  # Only for ACF/PACF as Plotly doesn't support these directly\n",
    "\n",
    "# === 1. Load combined dataset ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "# === 2. Select zone and calculate log returns ===\n",
    "zone = 'LZ_HOUSTON'\n",
    "price_col = f'{zone}_rtm'\n",
    "df = df[['datetime', price_col, 'wind_mw', 'solar_mw', 'net_output_mw']].copy()\n",
    "df = df[df[price_col] > 0]  # Filter out non-positive prices\n",
    "\n",
    "# Calculate log returns\n",
    "df['log_return'] = np.log(df[price_col]).diff() * 100\n",
    "\n",
    "# Drop rows with NaN or inf in log_return\n",
    "df['log_return'] = df['log_return'].replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(subset=['log_return'])\n",
    "\n",
    "# === Trim extreme outliers in log return ===\n",
    "outlier_threshold = 300\n",
    "df['log_return'] = df['log_return'].clip(lower=-outlier_threshold, upper=outlier_threshold)\n",
    "\n",
    "# === 3. Plot distribution of trimmed returns ===\n",
    "fig = px.histogram(df, x='log_return', nbins=100, marginal='rug',\n",
    "                   title=f'Trimmed Log Return Distribution â€“ {zone}',\n",
    "                   labels={'log_return': 'Log Return (%)'})\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()\n",
    "\n",
    "# === 4. ADF Test ===\n",
    "adf_result = adfuller(df['log_return'])\n",
    "print(f\"ADF Statistic: {adf_result[0]:.4f}\")\n",
    "print(f\"p-value: {adf_result[1]:.4f}\")\n",
    "\n",
    "# === 5. ACF/PACF Plots (Matplotlib) ===\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8))\n",
    "plot_acf(df['log_return'], lags=40, ax=ax[0])\n",
    "plot_pacf(df['log_return'], lags=40, ax=ax[1])\n",
    "ax[0].set_title('ACF of Log Returns')\n",
    "ax[1].set_title('PACF of Log Returns')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === 6. Fit GARCH(1,1) model ===\n",
    "log_returns_clean = df['log_return'].dropna()\n",
    "model_garch = arch_model(log_returns_clean, vol='Garch', p=1, q=1)\n",
    "res_garch = model_garch.fit(disp='off')\n",
    "df = df.loc[log_returns_clean.index].copy()\n",
    "df['volatility_garch'] = res_garch.conditional_volatility.values\n",
    "\n",
    "print(\"\\nGARCH(1,1) Parameters:\")\n",
    "print(res_garch.summary())\n",
    "\n",
    "# === 7. Fit EGARCH(1,1) with t-distribution ===\n",
    "model_egarch = arch_model(log_returns_clean, vol='EGarch', p=1, q=1, dist='t')\n",
    "res_egarch = model_egarch.fit(disp='off')\n",
    "df['volatility_egarch'] = res_egarch.conditional_volatility.values\n",
    "\n",
    "print(\"\\nEGARCH(1,1) Parameters (t-distribution):\")\n",
    "print(res_egarch.summary())\n",
    "\n",
    "# === 8. Plot both volatilities ===\n",
    "fig = px.line(df, x='datetime', y=['volatility_garch', 'volatility_egarch'],\n",
    "              title=f'GARCH vs EGARCH (t-dist) Conditional Volatility â€“ {zone}',\n",
    "              labels={'value': 'Volatility (%)', 'datetime': 'Date', 'variable': 'Model'})\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()\n",
    "\n",
    "# === 9. Segment and compare volatility (before/after 2024) ===\n",
    "df['period'] = np.where(df['datetime'] < '2024-01-01', 'pre_BESS', 'post_BESS')\n",
    "mean_vols = df.groupby('period')[['volatility_garch', 'volatility_egarch']].mean()\n",
    "print(\"\\nAverage Volatility by Period:\")\n",
    "print(mean_vols)\n",
    "\n",
    "# === 10. Scatter matrix: volatility vs renewables/BESS ===\n",
    "fig = px.scatter_matrix(df.dropna(subset=['volatility_egarch', 'wind_mw', 'solar_mw', 'net_output_mw']),\n",
    "                        dimensions=['volatility_egarch', 'wind_mw', 'solar_mw', 'net_output_mw'],\n",
    "                        title='EGARCH Volatility vs Renewables and BESS')\n",
    "fig.update_layout(template='plotly_white', height=700)\n",
    "fig.show()\n",
    "\n",
    "# === Ready for future: GARCH-X (with exogenous variables) ===\n",
    "# Example:\n",
    "# model_garchx = arch_model(log_returns_clean, vol='Garch', p=1, q=1, x=df[['wind_mw', 'solar_mw', 'net_output_mw']].shift(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ercot_volatility_analysis.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from arch import arch_model\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# === 1. Load data ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "# === 2. Preprocessing ===\n",
    "zone = 'LZ_HOUSTON'\n",
    "price_col = f'{zone}_rtm'\n",
    "df = df[['datetime', price_col, 'wind_mw', 'solar_mw', 'net_output_mw']].copy()\n",
    "df = df[df[price_col] > 0]\n",
    "df['log_return'] = np.log(df[price_col]).diff() * 100\n",
    "df['log_return'] = df['log_return'].replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(subset=['log_return'])\n",
    "df['log_return'] = df['log_return'].clip(-300, 300)\n",
    "\n",
    "# === 3. ADF Test ===\n",
    "adf_stat, p_value, *_ = adfuller(df['log_return'])\n",
    "print(f\"ADF Statistic: {adf_stat:.4f}, p-value: {p_value:.4f}\")\n",
    "\n",
    "# === 4. ACF/PACF ===\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6))\n",
    "plot_acf(df['log_return'], lags=40, ax=ax[0])\n",
    "plot_pacf(df['log_return'], lags=40, ax=ax[1])\n",
    "ax[0].set_title('ACF of Log Returns')\n",
    "ax[1].set_title('PACF of Log Returns')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === 5. EGARCH Fit ===\n",
    "log_returns_clean = df['log_return']\n",
    "model_egarch = arch_model(log_returns_clean, vol='EGarch', p=1, q=1, dist='t')\n",
    "res_egarch = model_egarch.fit(disp='off')\n",
    "df['volatility_egarch'] = res_egarch.conditional_volatility.values\n",
    "print(res_egarch.summary())\n",
    "\n",
    "# === 6. Time series plot ===\n",
    "fig = px.line(df, x='datetime', y='volatility_egarch', title='EGARCH Volatility Over Time')\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()\n",
    "\n",
    "# === 7. Boxplot Pre vs Post BESS ===\n",
    "df['period'] = np.where(df['datetime'] < '2024-01-01', 'Pre-BESS', 'Post-BESS')\n",
    "fig = px.box(df, x='period', y='volatility_egarch', title='EGARCH Volatility Pre vs Post BESS')\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()\n",
    "\n",
    "# === 8. Scatter Matrix ===\n",
    "fig = px.scatter_matrix(df.dropna(subset=['volatility_egarch', 'wind_mw', 'solar_mw', 'net_output_mw']),\n",
    "                        dimensions=['volatility_egarch', 'wind_mw', 'solar_mw', 'net_output_mw'],\n",
    "                        title='EGARCH Volatility vs Renewables and BESS')\n",
    "fig.update_layout(template='plotly_white', height=700)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from arch import arch_model\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# === Load data ===\n",
    "df = pd.read_csv(r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\", parse_dates=['datetime'])\n",
    "\n",
    "# === Define zones to analyze ===\n",
    "zones = ['LZ_HOUSTON', 'LZ_NORTH', 'LZ_SOUTH', 'LZ_WEST']\n",
    "\n",
    "# === Results containers ===\n",
    "summary_list = []\n",
    "volatility_df = pd.DataFrame({'datetime': df['datetime']})\n",
    "\n",
    "# === Loop over zones ===\n",
    "for zone in zones:\n",
    "    price_col = f'{zone}_rtm'\n",
    "    if price_col not in df.columns:\n",
    "        print(f\"âŒ Missing column: {price_col}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    temp = df[['datetime', price_col]].copy()\n",
    "    temp = temp[temp[price_col] > 0].dropna()\n",
    "    temp['log_return'] = np.log(temp[price_col]).diff() * 100\n",
    "    temp['log_return'] = temp['log_return'].replace([np.inf, -np.inf], np.nan).clip(-300, 300)\n",
    "    temp = temp.dropna(subset=['log_return'])\n",
    "\n",
    "    # === Fit EGARCH(1,1) with t-distribution ===\n",
    "    model = arch_model(temp['log_return'], vol='EGarch', p=1, q=1, dist='t')\n",
    "    res = model.fit(disp='off')\n",
    "\n",
    "    vol_col = f\"{zone}_vol_egarch\"\n",
    "    volatility_df = volatility_df.merge(temp[['datetime']].assign(**{vol_col: res.conditional_volatility.values}), on='datetime', how='left')\n",
    "\n",
    "    # === Collect summary ===\n",
    "    summary_list.append({\n",
    "        'Zone': zone,\n",
    "        'LogLik': round(res.loglikelihood, 2),\n",
    "        'AIC': round(res.aic, 1),\n",
    "        'Î½ (t-dist)': round(res.params.get('nu', np.nan), 2),\n",
    "        'Ï‰': round(res.params.get('omega', np.nan), 4),\n",
    "        'Î±1': round(res.params.get('alpha[1]', np.nan), 4),\n",
    "        'Î²1': round(res.params.get('beta[1]', np.nan), 4),\n",
    "        'mu': round(res.params.get('mu', np.nan), 4)\n",
    "    })\n",
    "\n",
    "# === Create summary table ===\n",
    "summary_df = pd.DataFrame(summary_list)\n",
    "print(\"\\nðŸ“Š EGARCH Model Summary Per Zone:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# === Plot 4 volatility curves as subplots ===\n",
    "fig = make_subplots(rows=2, cols=2, shared_xaxes=True, subplot_titles=zones)\n",
    "\n",
    "positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "\n",
    "for i, zone in enumerate(zones):\n",
    "    vol_col = f\"{zone}_vol_egarch\"\n",
    "    if vol_col not in volatility_df.columns:\n",
    "        continue\n",
    "    row, col = positions[i]\n",
    "    fig.add_trace(go.Scatter(x=volatility_df['datetime'], y=volatility_df[vol_col],\n",
    "                             mode='lines', name=zone,\n",
    "                             line=dict(width=1)), row=row, col=col)\n",
    "\n",
    "fig.update_layout(title='EGARCH Conditional Volatility by Zone',\n",
    "                  template='plotly_white', height=700, showlegend=False)\n",
    "fig.update_xaxes(title_text='Date')\n",
    "fig.update_yaxes(title_text='Volatility (%)')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d660e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Define cutoff\n",
    "cutoff = pd.to_datetime(\"2024-01-01\")\n",
    "\n",
    "# Smoothing: 1-month rolling average (hourly data = 24*30 = 720)\n",
    "window_hours = 720\n",
    "zones = ['LZ_HOUSTON', 'LZ_NORTH', 'LZ_SOUTH', 'LZ_WEST']\n",
    "vol_df = volatility_df.copy()\n",
    "\n",
    "# Create smoothed series and flag pre/post-BESS\n",
    "for zone in zones:\n",
    "    col = f\"{zone}_vol_egarch\"\n",
    "    vol_df[f\"{col}_smooth\"] = vol_df[col].rolling(window=window_hours, min_periods=1).mean()\n",
    "vol_df['period'] = np.where(vol_df['datetime'] < cutoff, 'Pre-BESS', 'Post-BESS')\n",
    "\n",
    "# Plotting\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=zones, shared_xaxes=True, shared_yaxes=True)\n",
    "\n",
    "positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "\n",
    "for i, zone in enumerate(zones):\n",
    "    row, col = positions[i]\n",
    "    col_smooth = f\"{zone}_vol_egarch_smooth\"\n",
    "    \n",
    "    pre = vol_df[vol_df['datetime'] < cutoff]\n",
    "    post = vol_df[vol_df['datetime'] >= cutoff]\n",
    "    \n",
    "    # Add pre-BESS smoothed line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pre['datetime'], y=pre[col_smooth],\n",
    "        mode='lines', name=f\"{zone} Pre-BESS\",\n",
    "        line=dict(color='gray'), showlegend=False\n",
    "    ), row=row, col=col)\n",
    "\n",
    "    # Add post-BESS smoothed line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=post['datetime'], y=post[col_smooth],\n",
    "        mode='lines', name=f\"{zone} Post-BESS\",\n",
    "        line=dict(color='steelblue'), showlegend=False\n",
    "    ), row=row, col=col)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=700, width=1100,\n",
    "    title_text=\"Rolling EGARCH Volatility by Zone (Pre/Post BESS)\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.update_yaxes(title_text=\"Volatility (%)\")\n",
    "fig.update_xaxes(title_text=\"Date\")\n",
    "fig.update_xaxes(showticklabels=True, tickformat=\"%Y\")  # Show year labels\n",
    "fig.update_layout(xaxis_showticklabels=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b38226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c29083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2593822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca52014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879b936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76a85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa420a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bda381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d26e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2ef2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ercot_volatility_analysis.py (Enhanced with diagnostics)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from arch import arch_model\n",
    "from matplotlib import cm\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch\n",
    "\n",
    "# === Load dataset ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "full_df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "# === Define zones and colormap ===\n",
    "zones = ['LZ_HOUSTON', 'LZ_NORTH', 'LZ_SOUTH', 'LZ_WEST']\n",
    "colorscale = cm.get_cmap('Blues', 4)\n",
    "\n",
    "zone_colors = {\n",
    "    zone: 'rgba({},{},{},{})'.format(*((np.array(colorscale(i)[:3]) * 255).astype(int)), 0.6)\n",
    "    for i, zone in enumerate(zones)\n",
    "}\n",
    "\n",
    "bess_start_date = pd.to_datetime('2024-01-01')\n",
    "fig_bess = make_subplots(\n",
    "    rows=2, cols=2, subplot_titles=zones,\n",
    "    vertical_spacing=0.12, horizontal_spacing=0.08\n",
    ")\n",
    "\n",
    "summary_table = []\n",
    "\n",
    "for i, zone in enumerate(zones):\n",
    "    price_col = f'{zone}_rtm'\n",
    "    df = full_df[['datetime', price_col]].copy()\n",
    "    df = df[df[price_col] > 0]\n",
    "    df['log_return'] = np.log(df[price_col]).diff().replace([np.inf, -np.inf], np.nan).clip(-3, 3)\n",
    "    df = df.dropna(subset=['log_return'])\n",
    "\n",
    "    df_pre = df[df['datetime'] < bess_start_date].copy()\n",
    "    df_post = df[df['datetime'] >= bess_start_date].copy()\n",
    "\n",
    "    try:\n",
    "        res_pre = arch_model(df_pre['log_return'] * 100, vol='Garch', p=1, q=1).fit(disp='off')\n",
    "        df_pre['vol'] = res_pre.conditional_volatility\n",
    "    except:\n",
    "        df_pre['vol'] = np.nan\n",
    "\n",
    "    try:\n",
    "        res_post = arch_model(df_post['log_return'] * 100, vol='Garch', p=1, q=1).fit(disp='off')\n",
    "        df_post['vol'] = res_post.conditional_volatility\n",
    "    except:\n",
    "        df_post['vol'] = np.nan\n",
    "\n",
    "    df_pre['year'] = df_pre['datetime'].dt.year\n",
    "    df_post['year'] = df_post['datetime'].dt.year\n",
    "    avg_yearly = pd.concat([df_pre, df_post]).groupby('year')['vol'].mean().reset_index()\n",
    "\n",
    "    # Rolling average\n",
    "    df_pre['rolling_vol'] = df_pre['vol'].rolling(24 * 30).mean()\n",
    "    df_post['rolling_vol'] = df_post['vol'].rolling(24 * 30).mean()\n",
    "\n",
    "    r, c = i // 2 + 1, i % 2 + 1\n",
    "    color = zone_colors[zone]\n",
    "\n",
    "    fig_bess.add_trace(go.Scatter(\n",
    "        x=df_pre['datetime'], y=df_pre['rolling_vol'], mode='lines',\n",
    "        name=f'{zone} Pre-BESS', line=dict(color='lightgray', width=1.2),\n",
    "        showlegend=(i == 0)\n",
    "    ), row=r, col=c)\n",
    "\n",
    "    fig_bess.add_trace(go.Scatter(\n",
    "        x=df_post['datetime'], y=df_post['rolling_vol'], mode='lines',\n",
    "        name=f'{zone} Post-BESS', line=dict(color=color, width=1.5),\n",
    "        showlegend=(i == 0)\n",
    "    ), row=r, col=c)\n",
    "\n",
    "    fig_bess.add_trace(go.Scatter(\n",
    "        x=avg_yearly['year'], y=avg_yearly['vol'],\n",
    "        mode='lines+text', line=dict(color='black', dash='dash'),\n",
    "        text=avg_yearly['vol'].round(1), textposition='top right',\n",
    "        name=f'{zone} Yearly Avg', showlegend=False\n",
    "    ), row=r, col=c)\n",
    "\n",
    "    # Summary stats and statistical tests\n",
    "    mean_pre = df_pre['vol'].mean()\n",
    "    mean_post = df_post['vol'].mean()\n",
    "    std_pre = df_pre['vol'].std()\n",
    "    std_post = df_post['vol'].std()\n",
    "    _, p_ttest = ttest_ind(df_pre['vol'].dropna(), df_post['vol'].dropna(), equal_var=False)\n",
    "    _, p_mw = mannwhitneyu(df_pre['vol'].dropna(), df_post['vol'].dropna(), alternative='two-sided')\n",
    "\n",
    "    # Residual diagnostics (only on post)\n",
    "    lb_pval = het_arch(res_post.resid.dropna())[1] if res_post else np.nan\n",
    "    arch_pval = acorr_ljungbox(res_post.resid.dropna(), lags=[12], return_df=True)['lb_pvalue'].iloc[0] if res_post else np.nan\n",
    "\n",
    "    summary_table.append([\n",
    "        zone, round(mean_pre, 2), round(mean_post, 2),\n",
    "        round(std_pre, 1), round(std_post, 1),\n",
    "        round(p_ttest, 4), round(p_mw, 4), round(lb_pval, 4), round(arch_pval, 4)\n",
    "    ])\n",
    "\n",
    "# Set subplot font size and layout\n",
    "for ann in fig_bess['layout']['annotations']:\n",
    "    ann['font'] = dict(size=14)\n",
    "\n",
    "fig_bess.update_layout(\n",
    "    height=950,\n",
    "    title=\"Rolling GARCH Volatility â€“ Pre vs Post BESS\",\n",
    "    plot_bgcolor='white',\n",
    "    font=dict(family=\"Arial\", size=12),\n",
    "    margin=dict(l=40, r=40, t=60, b=40)\n",
    ")\n",
    "fig_bess.show()\n",
    "\n",
    "# Print statistical summary\n",
    "sum_df = pd.DataFrame(summary_table, columns=[\n",
    "    \"Zone\", \"Pre-BESS Mean\", \"Post-BESS Mean\", \"Pre Std\", \"Post Std\",\n",
    "    \"p-value (t-test)\", \"p-value (MWU)\", \"ARCH Test (p)\", \"Ljung-Box (p)\"\n",
    "])\n",
    "print(\"\\nStatistical Summary of Volatility Pre vs Post BESS:\")\n",
    "print(sum_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e051cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ercot_volatility_analysis.py (Enhanced with diagnostics and GARCH-X)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from arch import arch_model\n",
    "from matplotlib import cm\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch\n",
    "\n",
    "# === Load dataset ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "full_df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "# === Define zones and colormap ===\n",
    "zones = ['LZ_HOUSTON', 'LZ_NORTH', 'LZ_SOUTH', 'LZ_WEST']\n",
    "colorscale = cm.get_cmap('Blues', 4)\n",
    "\n",
    "zone_colors = {\n",
    "    'LZ_HOUSTON': 'rgba(40, 80, 180, 1.0)',   # custom dark blue\n",
    "    'LZ_NORTH': 'rgba(80, 120, 200, 1.0)',\n",
    "    'LZ_SOUTH': 'rgba(120, 160, 220, 1.0)',\n",
    "    'LZ_WEST': 'rgba(160, 200, 240, 1.0)'\n",
    "}\n",
    "\n",
    "bess_start_date = pd.to_datetime('2024-01-01')\n",
    "fig_bess = make_subplots(\n",
    "    rows=2, cols=2, subplot_titles=zones,\n",
    "    vertical_spacing=0.12, horizontal_spacing=0.08\n",
    ")\n",
    "\n",
    "summary_table = []\n",
    "\n",
    "for i, zone in enumerate(zones):\n",
    "    price_col = f'{zone}_rtm'\n",
    "    df = full_df[['datetime', price_col, 'wind_mw', 'solar_mw']].copy()\n",
    "    df = df[df[price_col] > 0]\n",
    "    df['log_return'] = np.log(df[price_col]).diff().replace([np.inf, -np.inf], np.nan).clip(-3, 3)\n",
    "    df = df.dropna(subset=['log_return'])\n",
    "\n",
    "    df['wind_std'] = df['wind_mw'].rolling(24).std().fillna(method='bfill')\n",
    "    df['solar_std'] = df['solar_mw'].rolling(24).std().fillna(method='bfill')\n",
    "\n",
    "    df_pre = df[df['datetime'] < bess_start_date].copy()\n",
    "    df_post = df[df['datetime'] >= bess_start_date].copy()\n",
    "\n",
    "    try:\n",
    "        res_pre = arch_model(df_pre['log_return'] * 100, vol='Garch', p=1, q=1).fit(disp='off')\n",
    "        df_pre['vol'] = res_pre.conditional_volatility\n",
    "    except:\n",
    "        df_pre['vol'] = np.nan\n",
    "\n",
    "    try:\n",
    "        res_post = arch_model(df_post['log_return'] * 100, vol='Garch', p=1, q=1).fit(disp='off')\n",
    "        df_post['vol'] = res_post.conditional_volatility\n",
    "    except:\n",
    "        df_post['vol'] = np.nan\n",
    "\n",
    "    df_pre['year'] = df_pre['datetime'].dt.year\n",
    "    df_post['year'] = df_post['datetime'].dt.year\n",
    "    avg_yearly = pd.concat([df_pre, df_post]).groupby('year')['vol'].mean().reset_index()\n",
    "\n",
    "    # Rolling average\n",
    "    df_pre['rolling_vol'] = df_pre['vol'].rolling(24 * 30).mean()\n",
    "    df_post['rolling_vol'] = df_post['vol'].rolling(24 * 30).mean()\n",
    "\n",
    "    r, c = i // 2 + 1, i % 2 + 1\n",
    "    color = zone_colors[zone]\n",
    "\n",
    "    fig_bess.add_trace(go.Scatter(\n",
    "        x=df_pre['datetime'], y=df_pre['rolling_vol'], mode='lines',\n",
    "        name=f'{zone} Pre-BESS', line=dict(color='lightgray', width=1.2),\n",
    "        showlegend=(i == 0)\n",
    "    ), row=r, col=c)\n",
    "\n",
    "    fig_bess.add_trace(go.Scatter(\n",
    "        x=df_post['datetime'], y=df_post['rolling_vol'], mode='lines',\n",
    "        name=f'{zone} Post-BESS', line=dict(color=color, width=2.2),\n",
    "        showlegend=(i == 0)\n",
    "    ), row=r, col=c)\n",
    "\n",
    "    fig_bess.add_trace(go.Scatter(\n",
    "        x=avg_yearly['year'], y=avg_yearly['vol'],\n",
    "        mode='lines+text', line=dict(color='black', dash='dash'),\n",
    "        text=avg_yearly['vol'].round(1), textposition='top right',\n",
    "        name=f'{zone} Yearly Avg', showlegend=False\n",
    "    ), row=r, col=c)\n",
    "\n",
    "    # Summary stats and statistical tests\n",
    "    mean_pre = df_pre['vol'].mean()\n",
    "    mean_post = df_post['vol'].mean()\n",
    "    std_pre = df_pre['vol'].std()\n",
    "    std_post = df_post['vol'].std()\n",
    "    _, p_ttest = ttest_ind(df_pre['vol'].dropna(), df_post['vol'].dropna(), equal_var=False)\n",
    "    _, p_mw = mannwhitneyu(df_pre['vol'].dropna(), df_post['vol'].dropna(), alternative='two-sided')\n",
    "\n",
    "    # Residual diagnostics (only on post)\n",
    "    lb_pval = het_arch(res_post.resid.dropna())[1] if res_post else np.nan\n",
    "    arch_pval = acorr_ljungbox(res_post.resid.dropna(), lags=[12], return_df=True)['lb_pvalue'].iloc[0] if res_post else np.nan\n",
    "\n",
    "    summary_table.append([\n",
    "        zone, round(mean_pre, 2), round(mean_post, 2),\n",
    "        round(std_pre, 1), round(std_post, 1),\n",
    "        round(p_ttest, 4), round(p_mw, 4), round(lb_pval, 4), round(arch_pval, 4)\n",
    "    ])\n",
    "\n",
    "# Set subplot font size and layout\n",
    "for ann in fig_bess['layout']['annotations']:\n",
    "    ann['font'] = dict(size=14)\n",
    "\n",
    "fig_bess.update_layout(\n",
    "    height=950,\n",
    "    title=\"Rolling GARCH Volatility â€“ Pre vs Post BESS\",\n",
    "    plot_bgcolor='white',\n",
    "    font=dict(family=\"Arial\", size=12),\n",
    "    margin=dict(l=40, r=40, t=60, b=40)\n",
    ")\n",
    "fig_bess.show()\n",
    "\n",
    "# Plot Wind and Solar Daily Std Dev with Different Colors\n",
    "fig_ws = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=[\"Wind MW Daily Std Dev\", \"Solar MW Daily Std Dev\"])\n",
    "fig_ws.add_trace(go.Scatter(\n",
    "    x=full_df['datetime'], y=full_df['wind_mw'].rolling(24).std(),\n",
    "    line=dict(color='teal'), name=\"Wind Std Dev\"\n",
    "), row=1, col=1)\n",
    "fig_ws.add_trace(go.Scatter(\n",
    "    x=full_df['datetime'], y=full_df['solar_mw'].rolling(24).std(),\n",
    "    line=dict(color='orange'), name=\"Solar Std Dev\"\n",
    "), row=2, col=1)\n",
    "fig_ws.update_layout(title=\"Daily Std Dev of Wind and Solar (MW)\", height=700)\n",
    "fig_ws.show()\n",
    "\n",
    "# Print statistical summary\n",
    "sum_df = pd.DataFrame(summary_table, columns=[\n",
    "    \"Zone\", \"Pre-BESS Mean\", \"Post-BESS Mean\", \"Pre Std\", \"Post Std\",\n",
    "    \"p-value (t-test)\", \"p-value (MWU)\", \"ARCH Test (p)\", \"Ljung-Box (p)\"\n",
    "])\n",
    "sum_df.to_csv(\"volatility_summary_stats.csv\", index=False)\n",
    "print(\"\\nStatistical Summary of Volatility Pre vs Post BESS:\")\n",
    "print(sum_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ercot_volatility_analysis.py (Post-BESS GARCH-X Only)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from arch import arch_model\n",
    "\n",
    "# === Load dataset ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "full_df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "# === Define zones and colormap ===\n",
    "zones = ['LZ_HOUSTON', 'LZ_NORTH', 'LZ_SOUTH', 'LZ_WEST']\n",
    "zone_colors = {\n",
    "    'LZ_HOUSTON': 'rgba(20, 40, 90, 1.0)',\n",
    "    'LZ_NORTH': 'rgba(40, 60, 120, 1.0)',\n",
    "    'LZ_SOUTH': 'rgba(60, 90, 150, 1.0)',\n",
    "    'LZ_WEST': 'rgba(80, 120, 180, 1.0)'\n",
    "}\n",
    "\n",
    "bess_start_date = pd.to_datetime('2024-01-01')\n",
    "fig_gx = make_subplots(\n",
    "    rows=2, cols=2, subplot_titles=zones,\n",
    "    vertical_spacing=0.12, horizontal_spacing=0.08\n",
    ")\n",
    "\n",
    "def safe_post_garchx(data, exog_cols):\n",
    "    X = data[exog_cols].copy()\n",
    "    low_var_cols = [col for col in exog_cols if X[col].std() < 1e-3 or X[col].isna().all()]\n",
    "    X = X.drop(columns=low_var_cols)\n",
    "    if X.shape[1] == 0:\n",
    "        return None, np.nan, np.nan, np.nan\n",
    "    try:\n",
    "        model = arch_model(data['log_return'] * 100, vol='Garch', p=1, q=1, x=X)\n",
    "        result = model.fit(disp='off')\n",
    "        coefs = [result.params.get(f'x{i+1}', np.nan) for i in range(len(X.columns))]\n",
    "        return result, *coefs + [np.nan] * (3 - len(coefs))\n",
    "    except:\n",
    "        return None, np.nan, np.nan, np.nan\n",
    "\n",
    "coeff_table = []\n",
    "\n",
    "for i, zone in enumerate(zones):\n",
    "    price_col = f'{zone}_rtm'\n",
    "    df = full_df[['datetime', price_col, 'wind_mw', 'solar_mw', 'charging_mw', 'discharging_mw', 'net_output_mw']].copy()\n",
    "    df = df[df[price_col] > 0]\n",
    "    df['log_return'] = np.log(df[price_col]).diff().replace([np.inf, -np.inf], np.nan).clip(-3, 3)\n",
    "    df = df.dropna(subset=['log_return'])\n",
    "\n",
    "    df['wind_std'] = df['wind_mw'].rolling(24).std().fillna(method='bfill')\n",
    "    df['solar_std'] = df['solar_mw'].rolling(24).std().fillna(method='bfill')\n",
    "    df['bess_std'] = df['net_output_mw'].rolling(24).std().fillna(method='bfill')\n",
    "\n",
    "    df_post = df[df['datetime'] >= bess_start_date].copy()\n",
    "    res_post, wind_post, solar_post, bess_post = safe_post_garchx(df_post, ['wind_std', 'solar_std', 'bess_std'])\n",
    "\n",
    "    if res_post:\n",
    "        df_post['vol'] = res_post.conditional_volatility\n",
    "    else:\n",
    "        df_post['vol'] = np.nan\n",
    "\n",
    "    coeff_table.append({\n",
    "        'Zone': zone, 'Period': 'Post-BESS',\n",
    "        'Wind Coef': wind_post, 'Solar Coef': solar_post, 'BESS Coef': bess_post\n",
    "    })\n",
    "\n",
    "    df_post['rolling_vol'] = df_post['vol'].rolling(24 * 30).mean()\n",
    "    r, c = i // 2 + 1, i % 2 + 1\n",
    "    color = zone_colors[zone]\n",
    "\n",
    "    fig_gx.add_trace(go.Scatter(\n",
    "        x=df_post['datetime'], y=df_post['rolling_vol'], mode='lines',\n",
    "        name=f'{zone} Post-BESS', line=dict(color=color, width=2.5),\n",
    "        showlegend=(i == 0)\n",
    "    ), row=r, col=c)\n",
    "\n",
    "fig_gx.update_layout(\n",
    "    height=900,\n",
    "    title=\"GARCH-X Volatility (Post-BESS only): Wind, Solar, BESS as Exogenous Variables\",\n",
    "    plot_bgcolor='white',\n",
    "    font=dict(family=\"Arial\", size=12),\n",
    "    margin=dict(l=40, r=40, t=60, b=40)\n",
    ")\n",
    "fig_gx.show()\n",
    "\n",
    "# === Coefficient Table ===\n",
    "coef_df = pd.DataFrame(coeff_table)\n",
    "print(\"\\n=== GARCH-X Coefficients (Post-BESS Only) ===\")\n",
    "print(coef_df.round(4).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# === Load dataset ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "full_df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "# === Focus on one zone (e.g. LZ_HOUSTON) ===\n",
    "zone = 'LZ_HOUSTON'\n",
    "df = full_df[['datetime', f'{zone}_rtm', 'wind_mw', 'solar_mw', 'net_output_mw']].copy()\n",
    "df = df[df[f'{zone}_rtm'] > 0]\n",
    "\n",
    "# === Create volatility proxies (rolling std dev) ===\n",
    "df['wind_std'] = df['wind_mw'].rolling(24).std().bfill()\n",
    "df['solar_std'] = df['solar_mw'].rolling(24).std().bfill()\n",
    "df['bess_std'] = df['net_output_mw'].rolling(24).std().bfill()\n",
    "\n",
    "# === Filter post-BESS ===\n",
    "df = df[df['datetime'] >= '2024-01-01'].copy()\n",
    "df.dropna(subset=['wind_std', 'solar_std', 'bess_std'], inplace=True)\n",
    "\n",
    "# === Correlation matrix ===\n",
    "print(\"\\nðŸ”— Correlation Matrix:\")\n",
    "corr = df[['wind_std', 'solar_std', 'bess_std']].corr()\n",
    "print(corr.round(3))\n",
    "\n",
    "# === VIF calculation ===\n",
    "X = df[['wind_std', 'solar_std', 'bess_std']]\n",
    "X = (X - X.mean()) / X.std()  # Standardize\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Regressor'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(\"\\nðŸ“Š Variance Inflation Factor (VIF):\")\n",
    "print(vif_data)\n",
    "\n",
    "# === Optional heatmap ===\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Correlation Heatmap â€“ Volatility Regressors\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa29050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ercot_volatility_analysis.py (GARCH-X â€“ Single Regressor: Solar Only, Full Period + Summary Visuals)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from arch import arch_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load dataset ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "full_df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "# === Define zones ===\n",
    "zones = ['LZ_HOUSTON', 'LZ_NORTH', 'LZ_SOUTH', 'LZ_WEST']\n",
    "\n",
    "# === Prepare output ===\n",
    "results = []\n",
    "summary_labels = []\n",
    "\n",
    "for zone in zones:\n",
    "    price_col = f'{zone}_rtm'\n",
    "    df = full_df[['datetime', price_col, 'solar_mw']].copy()\n",
    "    df = df[df[price_col] > 0]\n",
    "    df['log_return'] = np.log(df[price_col]).diff().replace([np.inf, -np.inf], np.nan)\n",
    "    df['solar_std'] = df['solar_mw'].rolling(72).std().bfill()\n",
    "    df = df.dropna(subset=['log_return', 'solar_std'])\n",
    "\n",
    "    y = df['log_return'] * 100\n",
    "    x = df[['solar_std']]\n",
    "    x = (x - x.mean()) / x.std()\n",
    "\n",
    "    try:\n",
    "        model = arch_model(y, vol='Garch', p=1, q=1, x=x)\n",
    "        res = model.fit(disp='off')\n",
    "        coef = res.params.get('x[0]', np.nan)\n",
    "        pval = res.pvalues.get('x[0]', np.nan)\n",
    "        sig_label = (\n",
    "            \"âœ… Strong effect\" if pval < 0.01 else\n",
    "            \"ðŸ”¸ Weak effect\" if pval < 0.1 else\n",
    "            \"âŒ Not significant\"\n",
    "        )\n",
    "        summary_labels.append(f\"{zone}: {round(coef, 2)} ({sig_label})\")\n",
    "\n",
    "        print(f\"\\n[{zone} â€“ solar_std]\\n\")\n",
    "        print(res.summary())\n",
    "\n",
    "    except Exception as e:\n",
    "        coef = np.nan\n",
    "        pval = np.nan\n",
    "        summary_labels.append(f\"{zone}: model failed\")\n",
    "        print(f\"Model failed for {zone}: {e}\")\n",
    "\n",
    "    results.append({\n",
    "        'Zone': zone,\n",
    "        'Coef': round(coef, 4) if not pd.isna(coef) else np.nan,\n",
    "        'PVal': round(pval, 4) if not pd.isna(pval) else np.nan\n",
    "    })\n",
    "\n",
    "# === Display Results ===\n",
    "result_df = pd.DataFrame(results)\n",
    "print(\"\\n=== GARCH-X Solar Coefficients (Full Period) ===\")\n",
    "print(result_df.set_index('Zone'))\n",
    "\n",
    "# === Plot: Summary Bar Chart with Annotations ===\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=result_df['Zone'],\n",
    "    y=result_df['Coef'],\n",
    "    marker_color='darkorange',\n",
    "    text=summary_labels,\n",
    "    textposition=\"outside\"\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"GARCH-X Coefficients for Solar â€“ Full Period\",\n",
    "    xaxis_title=\"Zone\",\n",
    "    yaxis_title=\"Coefficient Value\",\n",
    "    height=500,\n",
    "    margin=dict(l=60, r=60, t=60, b=60)\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ercot_volatility_analysis.py (GARCH-X â€“ Single Regressor: Solar Only, Full Period + Summary Visuals + Volatility Trend Plots)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from arch import arch_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load dataset ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "full_df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "# === Define zones ===\n",
    "zones = ['LZ_HOUSTON', 'LZ_NORTH', 'LZ_SOUTH', 'LZ_WEST']\n",
    "\n",
    "# === Prepare output ===\n",
    "results = []\n",
    "summary_labels = []\n",
    "vol_trends = {}\n",
    "\n",
    "for zone in zones:\n",
    "    price_col = f'{zone}_rtm'\n",
    "    df = full_df[['datetime', price_col, 'solar_mw']].copy()\n",
    "    df = df[df[price_col] > 0]\n",
    "    df['log_return'] = np.log(df[price_col]).diff().replace([np.inf, -np.inf], np.nan)\n",
    "    df['solar_std'] = df['solar_mw'].rolling(72).std().bfill()\n",
    "    df = df.dropna(subset=['log_return', 'solar_std'])\n",
    "\n",
    "    y = df['log_return'] * 100\n",
    "    x = df[['solar_std']]\n",
    "    x = (x - x.mean()) / x.std()\n",
    "\n",
    "    try:\n",
    "        model = arch_model(y, vol='Garch', p=1, q=1, x=x)\n",
    "        res = model.fit(disp='off')\n",
    "        coef = res.params.get('x[0]', np.nan)\n",
    "        pval = res.pvalues.get('x[0]', np.nan)\n",
    "        cond_vol = res.conditional_volatility\n",
    "\n",
    "        df['cond_vol'] = cond_vol\n",
    "        vol_trends[zone] = df[['datetime', 'cond_vol', 'solar_std']].copy()\n",
    "\n",
    "        sig_label = (\n",
    "            \"âœ… Strong effect\" if pval < 0.01 else\n",
    "            \"ðŸ”¸ Weak effect\" if pval < 0.1 else\n",
    "            \"âŒ Not significant\"\n",
    "        )\n",
    "        summary_labels.append(f\"{zone}: {round(coef, 2)} ({sig_label})\")\n",
    "\n",
    "        print(f\"\\n[{zone} â€“ solar_std]\\n\")\n",
    "        print(res.summary())\n",
    "\n",
    "    except Exception as e:\n",
    "        coef = np.nan\n",
    "        pval = np.nan\n",
    "        summary_labels.append(f\"{zone}: model failed\")\n",
    "        print(f\"Model failed for {zone}: {e}\")\n",
    "\n",
    "    results.append({\n",
    "        'Zone': zone,\n",
    "        'Coef': round(coef, 4) if not pd.isna(coef) else np.nan,\n",
    "        'PVal': round(pval, 4) if not pd.isna(pval) else np.nan\n",
    "    })\n",
    "\n",
    "# === Display Results ===\n",
    "result_df = pd.DataFrame(results)\n",
    "print(\"\\n=== GARCH-X Solar Coefficients (Full Period) ===\")\n",
    "print(result_df.set_index('Zone'))\n",
    "\n",
    "# === Plot: Summary Bar Chart with Annotations ===\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=result_df['Zone'],\n",
    "    y=result_df['Coef'],\n",
    "    marker_color='darkorange',\n",
    "    text=summary_labels,\n",
    "    textposition=\"outside\"\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"GARCH-X Coefficients for Solar â€“ Full Period\",\n",
    "    xaxis_title=\"Zone\",\n",
    "    yaxis_title=\"Coefficient Value\",\n",
    "    height=500,\n",
    "    margin=dict(l=60, r=60, t=60, b=60)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# === Plot: Time Series of Volatility vs. Solar_STD ===\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 8), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, zone in enumerate(zones):\n",
    "    ax = axes[i]\n",
    "    if zone in vol_trends:\n",
    "        zdf = vol_trends[zone]\n",
    "        ax.plot(zdf['datetime'], zdf['cond_vol'], label='Volatility (GARCH)', color='navy')\n",
    "        ax.plot(zdf['datetime'], zdf['solar_std'], label='Solar Std Dev', color='orange', alpha=0.6)\n",
    "        ax.set_title(zone)\n",
    "        ax.set_ylabel(\"Scaled Values\")\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "fig.suptitle(\"Solar Variability vs. Conditional Volatility â€“ GARCH-X Trend\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ercot_volatility_analysis.py (GARCH-X â€“ Single Regressor: Wind + BESS, Full Period)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from arch import arch_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load dataset ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "full_df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "# === Define zones ===\n",
    "zones = ['LZ_HOUSTON', 'LZ_NORTH', 'LZ_SOUTH', 'LZ_WEST']\n",
    "\n",
    "# === Loop over regressors: wind and bess ===\n",
    "for regressor in ['wind_mw', 'net_output_mw']:\n",
    "    reg_label = 'Wind' if regressor == 'wind_mw' else 'BESS'\n",
    "    reg_std = regressor.replace('_mw', '_std')\n",
    "\n",
    "    results = []\n",
    "    summary_labels = []\n",
    "    vol_trends = {}\n",
    "\n",
    "    for zone in zones:\n",
    "        price_col = f'{zone}_rtm'\n",
    "        df = full_df[['datetime', price_col, regressor]].copy()\n",
    "        df = df[df[price_col] > 0]\n",
    "        df['log_return'] = np.log(df[price_col]).diff().replace([np.inf, -np.inf], np.nan)\n",
    "        df[reg_std] = df[regressor].rolling(72).std().bfill()\n",
    "        df = df.dropna(subset=['log_return', reg_std])\n",
    "\n",
    "        y = df['log_return'] * 100\n",
    "        x = df[[reg_std]]\n",
    "        x = (x - x.mean()) / x.std()\n",
    "\n",
    "        try:\n",
    "            model = arch_model(y, vol='Garch', p=1, q=1, x=x)\n",
    "            res = model.fit(disp='off')\n",
    "            coef = res.params.get('x[0]', np.nan)\n",
    "            pval = res.pvalues.get('x[0]', np.nan)\n",
    "            cond_vol = res.conditional_volatility\n",
    "\n",
    "            df['cond_vol'] = cond_vol\n",
    "            vol_trends[zone] = df[['datetime', 'cond_vol', reg_std]].copy()\n",
    "\n",
    "            sig_label = (\n",
    "                \"âœ… Strong effect\" if pval < 0.01 else\n",
    "                \"ðŸ”¸ Weak effect\" if pval < 0.1 else\n",
    "                \"âŒ Not significant\"\n",
    "            )\n",
    "            summary_labels.append(f\"{zone}: {round(coef, 2)} ({sig_label})\")\n",
    "\n",
    "            print(f\"\\n[{zone} â€“ {reg_std}]\")\n",
    "            print(res.summary())\n",
    "\n",
    "        except Exception as e:\n",
    "            coef = np.nan\n",
    "            pval = np.nan\n",
    "            summary_labels.append(f\"{zone}: model failed\")\n",
    "            print(f\"Model failed for {zone}: {e}\")\n",
    "\n",
    "        results.append({\n",
    "            'Zone': zone,\n",
    "            'Coef': round(coef, 4) if not pd.isna(coef) else np.nan,\n",
    "            'PVal': round(pval, 4) if not pd.isna(pval) else np.nan\n",
    "        })\n",
    "\n",
    "    # === Plot Coefficient Summary ===\n",
    "    result_df = pd.DataFrame(results)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=result_df['Zone'],\n",
    "        y=result_df['Coef'],\n",
    "        marker_color='teal' if regressor == 'wind_mw' else 'crimson',\n",
    "        text=summary_labels,\n",
    "        textposition=\"outside\"\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=f\"GARCH-X Coefficients for {reg_label} â€“ Full Period\",\n",
    "        xaxis_title=\"Zone\",\n",
    "        yaxis_title=\"Coefficient Value\",\n",
    "        height=500,\n",
    "        margin=dict(l=60, r=60, t=60, b=60)\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    # === Plot Time Series Trends ===\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 8), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, zone in enumerate(zones):\n",
    "        ax = axes[i]\n",
    "        if zone in vol_trends:\n",
    "            zdf = vol_trends[zone]\n",
    "            ax.plot(zdf['datetime'], zdf['cond_vol'], label='Volatility (GARCH)', color='navy')\n",
    "            ax.plot(zdf['datetime'], zdf[reg_std], label=f'{reg_label} Std Dev', alpha=0.6)\n",
    "            ax.set_title(zone)\n",
    "            ax.set_ylabel(\"Scaled Values\")\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "    fig.suptitle(f\"{reg_label} Variability vs. Conditional Volatility â€“ GARCH-X Trend\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a5519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e503017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d937d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b67a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from arch import arch_model\n",
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "\n",
    "# === Load and preprocess ===\n",
    "file_path = r\"C:\\Users\\amina.talipova\\Desktop\\ercot\\datasets\\ERCOT_all_hourly_2016.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=[\"datetime\"])\n",
    "\n",
    "zone = \"LZ_HOUSTON\"\n",
    "price_col = f\"{zone}_rtm\"\n",
    "\n",
    "# Filter and clean\n",
    "df = df[df[price_col] > 0].copy()\n",
    "df[\"log_return\"] = np.log(df[price_col]).diff().clip(-3, 3) * 100\n",
    "df[\"wind_std\"] = df[\"wind_mw\"].rolling(24).std().bfill()\n",
    "df = df.dropna(subset=[\"log_return\", \"wind_std\"])\n",
    "\n",
    "y = df[\"log_return\"]\n",
    "x = (df[[\"wind_std\"]] - df[[\"wind_std\"]].mean()) / df[[\"wind_std\"]].std()\n",
    "\n",
    "# === GARCH-X ===\n",
    "print(\"Fitting GARCH-X...\")\n",
    "model_garchx = arch_model(y, vol=\"Garch\", p=1, q=1, x=x)\n",
    "res_garchx = model_garchx.fit(disp=\"off\")\n",
    "print(res_garchx.summary())\n",
    "\n",
    "# === TGARCH (GJR-GARCH) ===\n",
    "print(\"\\nFitting TGARCH...\")\n",
    "model_tgarch = arch_model(y, vol=\"GARCH\", p=1, o=1, q=1)\n",
    "res_tgarch = model_tgarch.fit(disp=\"off\")\n",
    "print(res_tgarch.summary())\n",
    "\n",
    "# === Regime Switching ===\n",
    "print(\"\\nFitting Regime-Switching...\")\n",
    "model_rs = MarkovRegression(y, k_regimes=2, trend=\"c\", switching_variance=True)\n",
    "res_rs = model_rs.fit()\n",
    "print(res_rs.summary())\n",
    "\n",
    "# === Model Comparison ===\n",
    "print(\"\\n=== AIC / BIC Comparison ===\")\n",
    "aic_bic_df = pd.DataFrame({\n",
    "    \"Model\": [\"GARCH-X\", \"TGARCH\", \"Regime Switching\"],\n",
    "    \"AIC\": [res_garchx.aic, res_tgarch.aic, res_rs.aic],\n",
    "    \"BIC\": [res_garchx.bic, res_tgarch.bic, res_rs.bic]\n",
    "})\n",
    "print(aic_bic_df)\n",
    "\n",
    "# === Plot: Regime Probabilities ===\n",
    "res_rs.smoothed_marginal_probabilities[0].plot(figsize=(12, 4), title=\"Probability of Regime 0 (Low Volatility)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Plot: Conditional Volatility ===\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(res_garchx.conditional_volatility, label=\"GARCH-X\", alpha=0.8)\n",
    "plt.plot(res_tgarch.conditional_volatility, label=\"TGARCH\", alpha=0.8)\n",
    "plt.title(\"Conditional Volatility Comparison\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71adc99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2824d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d024e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
